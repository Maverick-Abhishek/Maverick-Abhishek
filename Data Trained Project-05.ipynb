{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34f21466",
   "metadata": {},
   "source": [
    "# Global Power Plant Database\n",
    "Problem Statement:\n",
    "Description\n",
    "\n",
    "The Global Power Plant Database is a comprehensive, open source database of power plants around the world. It centralizes power plant data to make it easier to navigate, compare and draw insights for oneâ€™s own analysis. The database covers approximately 35,000 power plants from 167 countries and includes thermal plants (e.g. coal, gas, oil, nuclear, biomass, waste, geothermal) and renewables (e.g. hydro, wind, solar). Each power plant is geolocated and entries contain information on plant capacity, generation, ownership, and fuel type. It will be continuously updated as data becomes available.\n",
    "\n",
    "Key attributes of the database\n",
    "The database includes the following indicators:\n",
    "\n",
    "`country` (text): 3 character country code corresponding to the ISO 3166-1 alpha-3 specification [5]\n",
    "`country_long` (text): longer form of the country designation\n",
    "`name` (text): name or title of the power plant, generally in Romanized form\n",
    "`gppd_idnr` (text): 10 or 12 character identifier for the power plant\n",
    "`capacity_mw` (number): electrical generating capacity in megawatts\n",
    "`latitude` (number): geolocation in decimal degrees; WGS84 (EPSG:4326)\n",
    "`longitude` (number): geolocation in decimal degrees; WGS84 (EPSG:4326)\n",
    "`primary_fuel` (text): energy source used in primary electricity generation or export\n",
    "`other_fuel1` (text): energy source used in electricity generation or export\n",
    "`other_fuel2` (text): energy source used in electricity generation or export\n",
    "`other_fuel3` (text): energy source used in electricity generation or export\n",
    " `commissioning_year` (number): year of plant operation, weighted by unit-capacity when data is available\n",
    "`owner` (text): majority shareholder of the power plant, generally in Romanized form\n",
    "`source` (text): entity reporting the data; could be an organization, report, or document, generally in Romanized form\n",
    "`url` (text): web document corresponding to the `source` field\n",
    "`geolocation_source` (text): attribution for geolocation information\n",
    "`wepp_id` (text): a reference to a unique plant identifier in the widely-used PLATTS-WEPP database.\n",
    "`year_of_capacity_data` (number): year the capacity information was reported\n",
    "`generation_gwh_2013` (number): electricity generation in gigawatt-hours reported for the year 2013\n",
    "`generation_gwh_2014` (number): electricity generation in gigawatt-hours reported for the year 2014\n",
    "`generation_gwh_2015` (number): electricity generation in gigawatt-hours reported for the year 2015\n",
    "`generation_gwh_2016` (number): electricity generation in gigawatt-hours reported for the year 2016\n",
    "`generation_gwh_2017` (number): electricity generation in gigawatt-hours reported for the year 2017\n",
    "`generation_gwh_2018` (number): electricity generation in gigawatt-hours reported for the year 2018\n",
    "`generation_gwh_2019` (number): electricity generation in gigawatt-hours reported for the year 2019\n",
    "`generation_data_source` (text): attribution for the reported generation information\n",
    "`estimated_generation_gwh_2013` (number): estimated electricity generation in gigawatt-hours for the year 2013\n",
    "`estimated_generation_gwh_2014` (number): estimated electricity generation in gigawatt-hours for the year 2014 \n",
    "`estimated_generation_gwh_2015` (number): estimated electricity generation in gigawatt-hours for the year 2015 \n",
    "`estimated_generation_gwh_2016` (number): estimated electricity generation in gigawatt-hours for the year 2016 \n",
    "`estimated_generation_gwh_2017` (number): estimated electricity generation in gigawatt-hours for the year 2017 \n",
    "'estimated_generation_note_2013` (text): label of the model/method used to estimate generation for the year 2013\n",
    "`estimated_generation_note_2014` (text): label of the model/method used to estimate generation for the year 2014 \n",
    "`estimated_generation_note_2015` (text): label of the model/method used to estimate generation for the year 2015\n",
    "`estimated_generation_note_2016` (text): label of the model/method used to estimate generation for the year 2016\n",
    "`estimated_generation_note_2017` (text): label of the model/method used to estimate generation for the year 2017 \n",
    "Fuel Type Aggregation\n",
    "We define the \"Fuel Type\" attribute of our database based on common fuel categories. \n",
    "\n",
    "Prediction :   Make two prediction  1) Primary Fuel    2) capacity_mw \n",
    "\n",
    "Find the dataset link below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056541bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import numpy as np # linear algebra\n",
    "import os # accessing directory structure\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e3c998",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir('C:\\\\Users\\\\win 7\\\\Desktop\\\\Datascience'))\n",
    "print(os.listdir('C:\\\\Users\\\\win 7\\\\Desktop\\\\Datascience\\\\Global Power Plant'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e711faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution graphs (histogram/bar graph) of column data\n",
    "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n",
    "    nunique = df.nunique()\n",
    "    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n",
    "    nRow, nCol = df.shape\n",
    "    columnNames = list(df)\n",
    "    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow\n",
    "    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n",
    "    for i in range(min(nCol, nGraphShown)):\n",
    "        plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n",
    "        columnDf = df.iloc[:, i]\n",
    "        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n",
    "            valueCounts = columnDf.value_counts()\n",
    "            valueCounts.plot.bar()\n",
    "        else:\n",
    "            columnDf.hist()\n",
    "        plt.ylabel('counts')\n",
    "         plt.xticks(rotation = 90)\n",
    "        plt.title(f'{columnNames[i]} (column {i})')\n",
    "    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cf5f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "def plotCorrelationMatrix(df, graphWidth):\n",
    "    filename = df.dataframeName\n",
    "    df = df.dropna('columns') # drop columns with NaN\n",
    "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
    "    if df.shape[1] < 2:\n",
    "        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n",
    "        return\n",
    "    corr = df.corr()\n",
    "    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n",
    "    corrMat = plt.matshow(corr, fignum = 1)\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "    plt.gca().xaxis.tick_bottom()\n",
    "    plt.colorbar(corrMat)\n",
    "    plt.title(f'Correlation Matrix for {filename}', fontsize=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc658912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter and density plots\n",
    "def plotScatterMatrix(df, plotSize, textSize):\n",
    "    df = df.select_dtypes(include =[np.number]) # keep only numerical columns\n",
    "    # Remove rows and columns that would lead to df being singular\n",
    "    df = df.dropna('columns')\n",
    "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
    "    columnNames = list(df)\n",
    "    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots\n",
    "        columnNames = columnNames[:10]\n",
    "    df = df[columnNames]\n",
    "    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')\n",
    "    corrs = df.corr().values\n",
    "    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n",
    "        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)\n",
    "    plt.suptitle('Scatter and Density Plot')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee42b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nRowsRead = 1000 # specify 'None' if want to read whole file\n",
    "# global_power_plant_database.csv may have more rows in reality, but we are only loading/previewing the first 1000 rows\n",
    "df1 = pd.read_csv(\"C:\\\\Users\\\\win 7\\\\Desktop\\\\Datascience\\\\Global Power Plant.csv\", delimiter=',', nrows = nRowsRead)\n",
    "df1.dataframeName = 'Global Power Plant.csv'\n",
    "nRow, nCol = df1.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52e9a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b0f0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotPerColumnDistribution(df1, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cddea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3587127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bcad66d",
   "metadata": {},
   "source": [
    "# Census Income Project\n",
    "Problem Statement:\n",
    "\n",
    "\n",
    "This data was extracted from the 1994 Census bureau database by Ronny Kohavi and Barry Becker (Data Mining and Visualization, Silicon Graphics). A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1) && (HRSWK>0)). The prediction task is to determine whether a person makes over $50K a year.\n",
    "\n",
    "Description of fnlwgt (final weight)\n",
    "The weights on the Current Population Survey (CPS) files are controlled to independent estimates of the civilian non-institutional population of the US. These are prepared monthly for us by Population Division here at the Census Bureau. We use 3 sets of controls. These are:\n",
    "\n",
    "A single cell estimate of the population 16+ for each state.\n",
    "\n",
    "Controls for Hispanic Origin by age and sex.\n",
    "\n",
    "Controls by Race, age and sex.\n",
    "\n",
    "We use all three sets of controls in our weighting program and \"rake\" through them 6 times so that by the end we come back to all the controls we used. The term estimate refers to population totals derived from CPS by creating \"weighted tallies\" of any specified socio-economic characteristics of the population. People with similar demographic characteristics should have similar weights. There is one important caveat to remember about this statement. That is that since the CPS sample is actually a collection of 51 state samples, each with its own probability of selection, the statement only applies within state.\n",
    "\n",
    "\n",
    "\n",
    "To download the dataset, use the link given below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b04ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from plotly.offline import iplot\n",
    "import plotly as py\n",
    "py.offline.init_notebook_mode(connected=True)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fd3981",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Census=pd.read_csv(r\"https://raw.githubusercontent.com/dsrscientist/dataset1/master/census_income.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b853d44",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_Census' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\WIN7~1\\AppData\\Local\\Temp/ipykernel_12504/3053069880.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_Census\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_Census' is not defined"
     ]
    }
   ],
   "source": [
    "df_Census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f85f9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census.info()\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 32560 entries, 0 to 32559\n",
    "Data columns (total 15 columns):\n",
    " #   Column          Non-Null Count  Dtype \n",
    "---  ------          --------------  ----- \n",
    " 0   Age             32560 non-null  int64 \n",
    " 1   Workclass       32560 non-null  object\n",
    " 2   Fnlwgt          32560 non-null  int64 \n",
    " 3   Education       32560 non-null  object\n",
    " 4   Education_num   32560 non-null  int64 \n",
    " 5   Marital_status  32560 non-null  object\n",
    " 6   Occupation      32560 non-null  object\n",
    " 7   Relationship    32560 non-null  object\n",
    " 8   Race            32560 non-null  object\n",
    " 9   Sex             32560 non-null  object\n",
    " 10  Capital_gain    32560 non-null  int64 \n",
    " 11  Capital_loss    32560 non-null  int64 \n",
    " 12  Hours_per_week  32560 non-null  int64 \n",
    " 13  Native_country  32560 non-null  object\n",
    " 14  Income          32560 non-null  object\n",
    "dtypes: int64(6), object(9)\n",
    "memory usage: 3.7+ MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2f6bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "0   Age             : The age of people\n",
    " 1   Workclass      : Type of job\n",
    " 2   Fnlwgt         : Final weight\n",
    " 3   Education      : Education status\n",
    " 4   Education_num  : Number of years of education in total\n",
    " 5   Marital_status : Marital_status\n",
    " 6   Occupation     : Occupation\n",
    " 7   Relationship   : Relationship\n",
    " 8   Race           : residential segregation\n",
    " 9   Sex            : Gender\n",
    " 10  Capital_gain   : Capital gain is the profit one earns\n",
    " 11  Capital_loss   : Capital gain is the profit one loose\n",
    " 12  Hours_per_week : Earning rate as per hrs\n",
    " 13  Native_country : Country\n",
    " 14  Income         : Income (Target variable)\n",
    "df_census.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e55d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census.isnull().sum()\n",
    "Age               0\n",
    "Workclass         0\n",
    "Fnlwgt            0\n",
    "Education         0\n",
    "Education_num     0\n",
    "Marital_status    0\n",
    "Occupation        0\n",
    "Relationship      0\n",
    "Race              0\n",
    "Sex               0\n",
    "Capital_gain      0\n",
    "Capital_loss      0\n",
    "Hours_per_week    0\n",
    "Native_country    0\n",
    "Income            0\n",
    "dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57dad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census['Native_country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9426f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census['Occupation'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2b6e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census.loc[df_census.Native_country==' ?']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac593801",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census.loc[df_census.Occupation==' ?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310e34dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census.drop(df_census[df_census['Native_country'] == ' ?'].index,inplace=True)\n",
    "# droping the bull values from both the columns\n",
    "df_census.drop(df_census[df_census['Occupation'] == ' ?'].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826abe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census['Native_country'].unique()\n",
    "array([' United-States', ' Cuba', ' Jamaica', ' India', ' Mexico',\n",
    "       ' South', ' Puerto-Rico', ' Honduras', ' England', ' Canada',\n",
    "       ' Germany', ' Iran', ' Philippines', ' Italy', ' Poland',\n",
    "       ' Columbia', ' Cambodia', ' Thailand', ' Ecuador', ' Laos',\n",
    "       ' Taiwan', ' Haiti', ' Portugal', ' Dominican-Republic',\n",
    "       ' El-Salvador', ' France', ' Guatemala', ' China', ' Japan',\n",
    "       ' Yugoslavia', ' Peru', ' Outlying-US(Guam-USVI-etc)', ' Scotland',\n",
    "       ' Trinadad&Tobago', ' Greece', ' Nicaragua', ' Vietnam', ' Hong',\n",
    "       ' Ireland', ' Hungary', ' Holand-Netherlands'], dtype=object)\n",
    "df_census.drop(df_census[df_census['Occupation'] == ' ?'].index,inplace=True)  # removeing the unnamed values\n",
    "array([' Bachelors', ' HS-grad', ' 11th', ' Masters', ' 9th',\n",
    "       ' Some-college', ' Assoc-acdm', ' 7th-8th', ' Doctorate',\n",
    "       ' Assoc-voc', ' Prof-school', ' 5th-6th', ' 10th', ' Preschool',\n",
    "       ' 12th', ' 1st-4th'], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb5a88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census['Income'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af86faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.barplot(x='Occupation',y='Capital_gain',data=df_census,hue='Sex')\n",
    "plt.xticks(rotation=70)\n",
    "##Checking the distribution of Capital_gain and  Occupation as per gender##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ace0e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,18))\n",
    "sns.barplot(x='Education',y='Hours_per_week',data=df_census,hue='Income')\n",
    "##Checking the distribution of Education and  Hours_per_week as gender###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71495caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder() # label encoder \n",
    "df_census['Income']=le.fit_transform(df_census['Income']) df_census['Sex']=le.fit_transform(df_census['Sex'])\n",
    "#Converting 2 columns into binary \n",
    "df_census = pd.get_dummies(df_census,drop_first=True)\n",
    "pd.set_option('display.max_columns',100)#to display all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb731f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35926be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_col_sacle = df_census[['Age','Fnlwgt','Education_num','Hours_per_week']]\n",
    "train_scaler_col = scaler.fit_transform(train_col_sacle)\n",
    "train_scaler_col = pd.DataFrame(train_scaler_col,columns=train_col_sacle.columns)\n",
    "df_census['Age']= train_scaler_col['Age']\n",
    "df_census['Fnlwgt']= train_scaler_col['Fnlwgt']\n",
    "df_census['Education_num']= train_scaler_col['Education_num']\n",
    "df_census['Hours_per_week']= train_scaler_col['Hours_per_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc67c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_census.drop(['Income'],axis=1)\n",
    "y = df_census['Income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f64d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(X,y, test_size=0.30, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec4029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression() #Logistic Regression\n",
    "knn=KNeighborsClassifier() #KNearest Neibour \n",
    "dt=DecisionTreeClassifier() # Deciesion Tree\n",
    "rf=RandomForestClassifier() # Random Forest\n",
    "adb=AdaBoostClassifier()    # Adaboost Classifier \n",
    "svm=SVC()              # support vactor classifier        \n",
    "gdboost=GradientBoostingClassifier() #Gradient Boosting Classifier \n",
    "xgboost=XGBClassifier()  #Xtrim Gredient Boosting Classifier \n",
    "print(\"Model is created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f37b879",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "knn.fit(X_train,y_train)\n",
    "dt.fit(X_train,y_train)\n",
    "rf.fit(X_train,y_train)\n",
    "adb.fit(X_train,y_train)\n",
    "svm.fit(X_train,y_train)\n",
    "gdboost.fit(X_train,y_train)\n",
    "xgboost.fit(X_train,y_train)\n",
    "print(\"Model is trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52efbe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lr classification score\",lr.score(X_train,y_train))\n",
    "print(\"knn classification score\",knn.score(X_train,y_train))\n",
    "print(\"dt classification score\",dt.score(X_train,y_train))\n",
    "print(\"rf classification score\",rf.score(X_train,y_train))\n",
    "print(\"adb classification score\",adb.score(X_train,y_train))\n",
    "print(\"svm classification score\",svm.score(X_train,y_train))\n",
    "print(\"gdboost classification score\",gdboost.score(X_train,y_train))\n",
    "print(\"xgboost classification score\",xgboost.score(X_train,y_train))\n",
    "Lr classification score 0.8516483516483516\n",
    "knn classification score 0.8714948844259189\n",
    "dt classification score 1.0\n",
    "rf classification score 0.9999526335733232\n",
    "adb classification score 0.8606479727169383\n",
    "svm classification score 0.8598427434634331\n",
    "gdboost classification score 0.8682266009852216\n",
    "xgboost classification score 0.9067355058734369"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e1ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_yprad = lr.predict(X_test)\n",
    "knn_yprad = knn.predict(X_test)\n",
    "dt_yprad = dt.predict(X_test)\n",
    "rf_yprad = rf.predict(X_test)\n",
    "adb_yprad = adb.predict(X_test)\n",
    "svm_yprad = svm.predict(X_test)\n",
    "gdboost_yprad = gdboost.predict(X_test)\n",
    "xgboost_yprad = xgboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15af41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_conf_mat = confusion_matrix(y_test,lr_yprad)\n",
    "print(\"confusion matrix for lr_model\",'\\n',lr_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567bce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_conf_mat = confusion_matrix(y_test,knn_yprad)\n",
    "print(\"confusion matrix for knn_model\",'\\n',knn_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef49d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_conf_mat = confusion_matrix(y_test,dt_yprad)\n",
    "print(\"confusion matrix for dt_model\",'\\n',dt_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e799b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_conf_mat = confusion_matrix(y_test,rf_yprad)\n",
    "print(\"confusion matrix for lr_model\",'\\n',rf_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef1f249",
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_conf_mat = confusion_matrix(y_test,adb_yprad)\n",
    "print(\"confusion matrix for lr_model\",'\\n',adb_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e1962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_conf_mat = confusion_matrix(y_test,svm_yprad)\n",
    "print(\"confusion matrix for svm_model\",'\\n',svm_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fce69e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdboost_conf_mat = confusion_matrix(y_test,gdboost_yprad)\n",
    "print(\"confusion matrix for gdboost_model\",'\\n',gdboost_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528c4bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_conf_mat = confusion_matrix(y_test,xgboost_yprad)\n",
    "print(\"confusion matrix for xgboost_model\",'\\n',xgboost_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a79dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_report = classification_report(y_test,lr_yprad)\n",
    "print(\" lr classification_report\" ,'\\n',lr_report)\n",
    "\n",
    "knn_report = classification_report(y_test,knn_yprad)\n",
    "print(\" knn classification_report\" ,'\\n',knn_report)\n",
    "\n",
    "dt_report = classification_report(y_test,dt_yprad)\n",
    "print(\" dt classification_report\" ,'\\n',dt_report)\n",
    "\n",
    "\n",
    "rf_report = classification_report(y_test,rf_yprad)\n",
    "print(\" rf classification_report\" ,'\\n',rf_report)\n",
    "\n",
    "\n",
    "adb_report = classification_report(y_test,adb_yprad)\n",
    "print(\" adb classification_report\" ,'\\n',adb_report)\n",
    "\n",
    "\n",
    "svm_report = classification_report(y_test,svm_yprad)\n",
    "print(\" svm classification_report\" ,'\\n',svm_report)\n",
    "\n",
    "\n",
    "gdboost_report = classification_report(y_test,gdboost_yprad)\n",
    "print(\" gdboost classification_report\" ,'\\n',gdboost_report)\n",
    "\n",
    "\n",
    "xgboost_report = classification_report(y_test,xgboost_yprad)\n",
    "print(\" xgboost classification_report\" ,'\\n',xgboost_report)\n",
    "lr classification_report \n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.88      0.92      0.90      6820\n",
    "           1       0.71      0.61      0.66      2229\n",
    "\n",
    "    accuracy                           0.84      9049\n",
    "   macro avg       0.80      0.76      0.78      9049\n",
    "weighted avg       0.84      0.84      0.84      9049\n",
    "\n",
    " knn classification_report \n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.87      0.89      0.88      6820\n",
    "           1       0.63      0.58      0.60      2229\n",
    "\n",
    "    accuracy                           0.81      9049\n",
    "   macro avg       0.75      0.74      0.74      9049\n",
    "weighted avg       0.81      0.81      0.81      9049\n",
    "\n",
    " dt classification_report \n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.87      0.86      0.87      6820\n",
    "           1       0.60      0.62      0.61      2229\n",
    "\n",
    "    accuracy                           0.80      9049\n",
    "   macro avg       0.74      0.74      0.74      9049\n",
    "weighted avg       0.81      0.80      0.81      9049\n",
    "rf classification_report \n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.88      0.92      0.90      6820\n",
    "           1       0.71      0.62      0.66      2229\n",
    "\n",
    "    accuracy                           0.84      9049\n",
    "   macro avg       0.80      0.77      0.78      9049\n",
    "weighted avg       0.84      0.84      0.84      9049\n",
    "\n",
    " adb classification_report \n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.88      0.92      0.90      6820\n",
    "           1       0.75      0.60      0.67      2229\n",
    "\n",
    "    accuracy                           0.85      9049\n",
    "   macro avg       0.81      0.77      0.79      9049\n",
    "weighted avg       0.85      0.85      0.85      9049\n",
    "\n",
    " svm classification_report \n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.87      0.93      0.90      6820\n",
    "           1       0.72      0.56      0.63      2229\n",
    "\n",
    "    accuracy                           0.84      9049\n",
    "   macro avg       0.79      0.74      0.76      9049\n",
    "weighted avg       0.83      0.84      0.83      9049\n",
    "\n",
    " \n",
    "gdboost classification_report \n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.88      0.94      0.91      6820\n",
    "           1       0.77      0.61      0.68      2229\n",
    "\n",
    "    accuracy                           0.86      9049\n",
    "   macro avg       0.82      0.77      0.79      9049\n",
    "weighted avg       0.85      0.86      0.85      9049\n",
    "\n",
    " xgboost classification_report \n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.89      0.93      0.91      6820\n",
    "           1       0.75      0.67      0.70      2229\n",
    "\n",
    "    accuracy                           0.86      9049\n",
    "   macro avg       0.82      0.80      0.81      9049\n",
    "weighted avg       0.86      0.86      0.86      9049"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7c9ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "#importing the ric and auc from sklearn and predect the x_test and \n",
    "checking the roc_auc_score\n",
    "print(roc_auc_score(y_test,lr.predict(X_test)))\n",
    "print(roc_auc_score(y_test,knn.predict(X_test)))\n",
    "print(roc_auc_score(y_test,dt.predict(X_test)))\n",
    "print(roc_auc_score(y_test,rf.predict(X_test)))\n",
    "print(roc_auc_score(y_test,adb.predict(X_test)))\n",
    "print(roc_auc_score(y_test,svm.predict(X_test)))\n",
    "print(roc_auc_score(y_test,gdboost.predict(X_test)))\n",
    "print(roc_auc_score(y_test,xgboost.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bb9feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets find roc curve to check best fittted model\n",
    "disp = plot_roc_curve(dt,X_test,y_test)\n",
    "plot_roc_curve(lr,X_test,y_test,ax=disp.ax_)  # here ax_ for axis with confustion matrics\n",
    "plot_roc_curve(knn,X_test,y_test,ax=disp.ax_)\n",
    "plot_roc_curve(dt,X_test,y_test,ax=disp.ax_)\n",
    "plot_roc_curve(rf,X_test,y_test,ax=disp.ax_)\n",
    "plot_roc_curve(adb,X_test,y_test,ax=disp.ax_)\n",
    "plot_roc_curve(svm,X_test,y_test,ax=disp.ax_)\n",
    "plot_roc_curve(gdboost,X_test,y_test,ax=disp.ax_)\n",
    "plot_roc_curve(xgboost,X_test,y_test,ax=disp.ax_)\n",
    "plt.legend(prop = {'size':11}, loc ='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2d46ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "k_f = KFold(n_splits=4,shuffle=True)\n",
    "k_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53164f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean of Cross validation score for gdboost  model\",\"=>\",cross_val_score(gdboost,X,y,cv=5).mean())\n",
    "print(\"Cross validation score for xgboost model\",\"=>\",cross_val_score(xgboost,X,y,cv=5).mean())\n",
    "Cross validation score for gdboost  model => 0.8676757809940992\n",
    "Cross validation score for xgboost model => 0.8670137849256147"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df5d39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "xgboost.get_params().keys()  # to check the parameters\n",
    "parm_grid  = {'max_depth' : [3,4],\n",
    "              'subsample' : [0.5,0.8],\n",
    "              'learning_rate': [0.1],\n",
    "              'min_child_weight' : [1,2],\n",
    "              'random_state' : [4,5]}\n",
    "parm_grid\n",
    "{'max_depth': [3, 4],\n",
    " 'subsample': [0.5, 0.8],\n",
    " 'learning_rate': [0.1],\n",
    " 'min_child_weight': [1, 2],\n",
    " 'random_state': [4, 5]}\n",
    "\n",
    "#giving above parameters to our model and behalf of this will train it again.\n",
    "gridsearch = GridSearchCV(xgboost, param_grid = parm_grid , cv=5)\n",
    "#fit the model using given paramters\n",
    "gridsearch.fit(X_train,y_train)\n",
    "#traning the model now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddd7526",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch.best_params_\n",
    "#printing the best parameters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88efefa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_tuning=XGBClassifier(learning_rate=0.1,max_depth=4,min_child_weight=2,random_state=4,subsample=0.8)\n",
    "#supplying best parameters to our model\n",
    "xgboost_tuning.fit(X_train,y_train)\n",
    "#train the model\n",
    "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
    "              min_child_weight=2, missing=nan, monotone_constraints='()',\n",
    "              n_estimators=100, n_jobs=2, num_parallel_tree=1, random_state=4,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.8,\n",
    "              tree_method='exact', validate_parameters=1, \n",
    "#predicting the values using test data\n",
    "xgboost_tuning_yprad = xgboost_tuning.predict(X_test)\n",
    "\n",
    "#printing the classification report\n",
    "xgboost_report = classification_report(y_test,xgboost_tuning_yprad)\n",
    "print(\" xgboost classification_report\" ,'\\n',xgboost_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f25f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "Census_model = 'Census_model.pickle'\n",
    "pickle.dump(xgboost_tuning,open(Census_model,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c3df0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9d1ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e6cb225",
   "metadata": {},
   "source": [
    "# Loan Application Status Prediction\n",
    "Problem Statement:\n",
    "This dataset includes details of applicants who have applied for loan. The dataset includes details like credit history, loan amount, their income, dependents etc. \n",
    "\n",
    "Independent Variables:\n",
    "\n",
    "- Loan_ID\n",
    "\n",
    "- Gender\n",
    "\n",
    "- Married\n",
    "\n",
    "- Dependents\n",
    "\n",
    "- Education\n",
    "\n",
    "- Self_Employed\n",
    "\n",
    "- ApplicantIncome\n",
    "\n",
    "- CoapplicantIncome\n",
    "\n",
    "- Loan_Amount\n",
    "\n",
    "- Loan_Amount_Term\n",
    "\n",
    "- Credit History\n",
    "\n",
    "- Property_Area\n",
    "\n",
    "Dependent Variable (Target Variable):\n",
    "\n",
    "- Loan_Status\n",
    "\n",
    "You have to build a model that can predict whether the loan of the applicant will be approved or not on the basis of the details provided in the dataset. \n",
    "\n",
    "Note: The link of the dataset is below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fee18e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509a210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\win 7\\\\Desktop\\\\Datascience\\\\Loan Prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93181ae3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\WIN7~1\\AppData\\Local\\Temp/ipykernel_12504/3870928973.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110edf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efdcf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.apply(lambda x: sum(x.isnull()),axis=0) # checking missing values in each column of train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c3ce2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9e69ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Gender = data.Gender.fillna('Male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560b47fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Married'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2996deee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Married = data.Married.fillna('Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557f0e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Dependents'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5add7180",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Dependents = data.Dependents.fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5f4996",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Self_Employed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66efe05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Self_Employed = data.Self_Employed.fillna('No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4c39c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.LoanAmount = data.LoanAmount.fillna(data.LoanAmount.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2986edea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Loan_Amount_Term'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e21157",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Loan_Amount_Term = data.Loan_Amount_Term.fillna(360.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7911a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Credit_History'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d95ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Credit_History = data.Credit_History.fillna(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443ada8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.apply(lambda x: sum(x.isnull()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f31af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4e0687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting traing data\n",
    "X = data.iloc[:, 1: 12].values\n",
    "y = data.iloc[:, 12].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8263f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c93777",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8905c363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb5d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af881e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "# Encoding the Independent Variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55c48f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 5):\n",
    "    X_train[:,i] = labelencoder_X.fit_transform(X_train[:,i])\n",
    "\n",
    "X_train[:,10] = labelencoder_X.fit_transform(X_train[:,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db0ff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the Dependent Variable\n",
    "labelencoder_y = LabelEncoder()\n",
    "y_train = labelencoder_y.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c471aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f70d131",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd531a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "# Encoding the Independent Variable\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "for i in range(0, 5):\n",
    "    X_test[:,i] = labelencoder_X.fit_transform(X_test[:,i])\n",
    "X_test[:,10] = labelencoder_X.fit_transform(X_test[:,10])\n",
    "# Encoding the Dependent Variable\n",
    "labelencoder_y = LabelEncoder()\n",
    "y_test = labelencoder_y.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781dded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c960290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cb2d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 2)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.fit_transform(X_test)\n",
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24c9b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6df10ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2b0a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2840be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring Accuracy\n",
    "from sklearn import metrics\n",
    "print('The accuracy of Logistic Regression is: ', metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2fbfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e4a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91fbb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the Training set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_train, y_train\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('pink', 'lightgreen')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Logistic Regression (Training set)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56abb46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the Test set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_test, y_test\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('pink', 'lightgreen')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Logistic Regression (Test set)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd02047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting K-NN to the Training set\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e5a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab20455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401be160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring Accuracy\n",
    "from sklearn import metrics\n",
    "print('The accuracy of KNN is: ', metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517844a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3694aa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the Training set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_train, y_train\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('pink', 'lightgreen')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('KNN (Training set)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda631db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the Test set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_test, y_test\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('pink', 'lightgreen')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('KNN (Training set)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef442b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting SVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c3b9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07d85ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3437749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring Accuracy\n",
    "from sklearn import metrics\n",
    "print('The accuracy of SVM is: ', metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a261ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e178ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the Training set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_train, y_train\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('pink', 'lightgreen')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('SVM (Training set)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e27365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the Test set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_test, y_test\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('pink', 'lightgreen')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('SVM (Test set)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4157a253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Naive Bayes to the Training set\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013cf90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d3bd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658fd2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring Accuracy\n",
    "from sklearn import metrics\n",
    "print('The accuracy of Naive Bayes is: ', metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62dccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7d5636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the Training set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_train, y_train\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('pink', 'lightgreen')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Naive Bayes (Training set)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7179718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the Test set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_test, y_test\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('pink', 'lightgreen')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Naive Bayes (Test set)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691c906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Decision Tree Classification to the Training set\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa63a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4c01df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring Accuracy\n",
    "from sklearn import metrics\n",
    "print('The accuracy of Decision Tree Classifier is: ', metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f92ec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f19fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the Training set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_train, y_train\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('pink', 'lightgreen')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Decision Tree Classifier (Training set)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cea2169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the Test set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_test, y_test\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('pink', 'lightgreen')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Decision Tree Classifier (Test set)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4467b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Random Forest Classification to the Training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e85df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d09ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring Accuracy\n",
    "from sklearn import metrics\n",
    "print('The accuracy of Random Forest Classification is: ', metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8fd2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e83c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the Training set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_train, y_train\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('pink', 'lightgreen')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Random Forest Classification (Training set)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485dcedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the Test set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_test, y_test\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('pink', 'lightgreen')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Random Forest Classification (Test set)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbefb09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fbec84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
